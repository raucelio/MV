# Métodos Básicos de Imputação

## Métodos Básicos

### Listwise deletion

*Listwise deletion*  consiste em eliminar toda observação que apresente `NA` em uma de suas variáveis, é o comportamento padrão de lidar *missing values* em muitos pacotes estatísticos. A função `na.omit ()` faz o  R assumir esse comportamento, pois exclui do data frame toda observação com 'NA' em ao menos uma de suas variáveis.

A principal vantagem *listwise deletion* é a conveniência, se os dados forem MCAR, essa abordagem  produz estimativas não viesadas  para médias, variâncias e coeficeintes de uma regressão. 

No MCAR, a *listwise deletion*  produz erros padrão e níveis de significância que são corretos para o subconjunto reduzido de dados,
mas que geralmente são maiores em relação a todos os dados disponíveis.

Uma desvantagem da *listwise deletion* é a potencial perda de observações. Não é incomum em aplicações reais que mais da metade da amostra original seja perdida, especialmente se o número de variáveis for grande. 

<!-- King et al. (2001) estimaram que a porcentagem de registros incompletos nas ciências políticas ultrapassou 50% em média, com alguns estudos tendo mais de 90% de registros incompletos. -->

Uma subamostra menor pode dificultar a capacidade de detectar  os efeitos de interesse. Se os dados não forem MCAR, a *listwise deletio pode viesar as estimativas de médias, coeficientes de regressão e correlações. 

<!-- Little e Rubin (2002, pp. 41–44) mostraram que o viés  -->
<!-- na média estimada aumenta com a diferença entre as médias dos casos observados  e ausentes e com a proporção dos dados ausentes.  -->
<!-- Schafer e Graham (2002) relataram um elegante estudo de simulação que demonstra o viés da deleção listwise sob MAR e MNAR. -->
 
No entanto, a *listwise deletion* nem sempre é ruim. As implicações dos dados ausentes são diferentes dependendo de onde eles ocorrem (resultados ou preditores) e do parâmetro e forma do modelo da análise completa dos dados.  

No contexto da análise de regressão, a *listwise deletion*
o possui algumas propriedades exclusivas que a tornam atraente em ambientes específicos. Há casos em que a exclusão listwise pode fornecer estimativas melhores do que até mesmo os procedimentos mais sofisticados. 

A *Listwise deletion* pode introduzir inconsistências nos relatórios de uma pesquisa. Uma vez que a *listwise deletion*  é aplicada automaticamente ao conjunto ativo de variáveis,  análises diferentes nos mesmos dados são freqüentemente baseadas em diferentes subamostras. 
É possível produzir uma subamostra global usando todas as variáveis ativas.  Na prática, isso pode gerar problemas, pois a subamostra global sempre terá menos casos do que cada uma das subamostras, portanto, é comum criar subconjuntos diferentes para tabelas diferentes. Isso complica sua comparação e generalização para a população de estudo. Em alguns casos, a *listwise deletion*  pode levar
a subamostras sem sentido. Por exemplo, as observações no dataset *airquality*  correspondem a 154 dias consecutivos entre 1º de maio de
 1973 e 30 de setembro de 1973. A exclusão de dias afeta a base de tempo. Seria muito mais difícil, senão impossível, realizar análises que  envolvam tempo, por exemplo, para identificar padrões semanais ou ajustar modelos autorregressivos que preveem de dias anteriores.


### Dropping Variable

Caso uma  variável possuir mais de 60% de *missing values* nas observações, uma alternativa é retirar essa variável , mas somente se a variável for escencial a análise. Dito isto, a iputação é sempre uma escolha preferida em vez de eliminar variáveis. 


### Pairwise deletion

A *pairwise deletions*, também conhecida como análise de caso disponível, tenta remediar o problema de perda de observações que ocorrem na *listwise deletion*. 

O método calcula as médias e (co) variâncias para  todos os dados observados disponíveis. Assim, a média da variável X é baseada em todos os casos com dados observados em X, a média da variável Y usa todos os casos com valores de Y observados.  Para a correlação e covariância, todos os dados são considerados nos quais X e Y não são `NA`. Posteriormente, a matriz  é alimentada em um programa para análise de regressão, análise fatorial ou outros procedimentos de modelagem. 

Podemos calcular as covariâncias e as correlações dos dados no data frame airquality pelo proceddimento  *pairwise deletions* no R como:

```{r}
a <- cor(airquality, use = "pair") 
print(a, digits = 3)
a <-cov(airquality, use = "pair")
print(a,digits = 3)
```


O método é simples, usa todas as informações disponíveis e produz estimativas consistentes de média, correlações e covariâncias sob MCAR <!--- (Little e Rubin, 2002, p. 55)--->. No entanto, quando consideradas em  conjunto, essas estimativas apresentam deficiências importantes. As estimativas podem ser tendenciosas  se os dados não forem MCAR.  Além disso, existem problemas computacionais. A matriz de correlação pode não ser definida positivamente, o que é um requisito para a maioria procedimentos multivariados. Podem ocorrer correlações fora do intervalo [-1, + 1], um problema que vem de diferentes subconjuntos usados para as covariâncias e as variâncias.

Esses problemas são mais graves para variáveis altamente correlacionadas <!---(Little, 1992) --->. Outro problema é que não está claro qual tamanho de amostra deve ser usado para calcular os erros padrão. Tirar o tamanho médio da amostra resulta em erros padrão que são muito pequenos <!--- (Little, 1992)-->. A ideia 
por trás da exclusão aos pares é usar todas as informações disponíveis. Embora essa ideia seja boa, a análise adequada da matriz de pares  requer técnicas sofisticadas de otimização e fórmulas especiais para calcular os erros padrão <!--- (Van Praag et al., 1985; Marsh, 1998)--->.

<!---A Pairwise deletion deve ser usada apenas se o procedimento a seguir for especificamente projetado para levar a exclusão em consideração. A atraente simplicidade da exclusão aos pares como um método geral de dados perdidos é perdida.--->

### Mean imputation

A *mean imputation* é substituir o `NA` em uma variável pela média dos valores observados. No caso da variável ser categórica, o valor `NA` pode ser substituído pela moda.


```{r fig.align='center', fig.asp=.75, fig.cap='Dados Observados e imputados', message=FALSE, warning=FALSE, out.width='80%'}

library(ggplot2)

dados_observados <- data.frame(observado = na.omit(airquality$Ozone))

num_missing <- sum(is.na(airquality$Ozone))

dados_imputados  <- data.frame(imputado = rep(mean(airquality$Ozone,na.rm=T),
                                              num_missing))

ggplot()+
  geom_histogram(data = dados_observados, aes(x=observado), 
                 bins = 15, fill="blue", alpha = 0.5)+
  geom_histogram(data = dados_imputados, aes(x=imputado),
                 bins = 15, fill = "red", alpha = 0.5)+
  labs(x = "Valores da variável Ozone",
       y = "Frequência")


```

<!--O pacote `mice`  adota a convenção Abayomi para as cores (Abayomi et al., 2008). ---> 

A cor azul refere-se aos dados observados , vermelho aos dados imputados (também chamados de valores sintéticos ou imputações). A cor preta,  aos dados completos, e também chamados de imputados.

Na figura, a barra vermelha na média se destaca. Imputar a média criou uma distribuição bimodal. O desvio padrão nos dados completos é igual a 28.7, menor do que os dados observados, que é 33. 


A figura do lado direito mostra que a relação entre Ozônio e Solar.R é distorcida por causa das imputações. A correlação cai de 0,35 nos pontos azuis para 0,3 nos dados combinados. 

```{r fig.align='center', fig.asp=.75, fig.cap='Relação entre Ozone e Solar.R',  message=FALSE, warning=FALSE, out.width='80%'}

library(ggplot2)

dados <- na.omit(airquality[,c("Ozone", "Solar.R")])

dados_observados <- data.frame(dados)

dados_ausentes   <- airquality [is.na(airquality$Ozone) | 
                                is.na(airquality$Solar.R),
                                c("Ozone", "Solar.R") ]

Ozone_imputado <- ifelse (is.na(dados_ausentes$Ozone),
                          mean(dados_observados$Ozone),  
                          dados_ausentes$Ozone)

Solar.R_imputado <- ifelse (is.na(dados_ausentes$Solar.R),
                            mean(dados_observados$Solar.R),  
                            dados_ausentes$Solar.R)

dados_imputados  <- data.frame(Ozone = Ozone_imputado,
                               Solar.R = Solar.R_imputado)

ggplot()+
  geom_point(data = dados_observados, aes(y=Ozone, x=Solar.R), 
             color="blue", alpha = 0.5)+
  geom_point(data = dados_imputados, aes(y=Ozone, x = Solar.R),
             color = "red", alpha = 0.5)+
  labs(y = "Variável Ozone",
       x = "Variável Solar.R")


```

A imputação média é uma solução rápida e simples para os *missing values*. No entanto, subestima a variância, altera as relações entre as variáveis, enviesar quase qualquer estimativa diferente da média e enviesar a estimativa da média quando os dados não são MCAR.

A imputação média talvez deva ser usada apenas como uma correção rápida e deve ser evitada em geral.

### Regression imputation


A *Regression imputation* incorpora o conhecimento de outras variáveis com a ideia de produzir imputações mais inteligentes. A primeira etapa envolve a construção de um modelo a partir dos dados observados. As previsões para os casos incompletos são então calculadas de acordo com o modelo ajustado e servem como substitutos para os dados ausentes. 

Suponha que modelamos `Ozone` pela função de regressão linear de `Solar.R`.

```{r}
fit      <- lm (Ozone ~ Solar.R, data = airquality)
summary(fit)
pred  <- predict (fit, newdata = airquality[is.na(airquality$Ozone), ])
pred  <- data.frame (Ozone_imputado=pred, airquality[is.na(airquality$Ozone), ] )
pred  <- pred[!is.na(Ozone_imputado), ]
```

```{r fig.align='center', fig.asp=.75, fig.cap='Regression imputation entre Ozone e Solar.R',  message=FALSE, warning=FALSE, out.width='80%'}
dados <- na.omit(airquality[,c("Ozone", "Solar.R")])
dados_observados <- data.frame(dados)
Ozone_imputado <- pred

ggplot()+
  geom_point(data = dados_observados, aes(y=Ozone, x=Solar.R), 
             color="blue", alpha = 0.5)+
  geom_point(data = Ozone_imputado, 
             aes(y=Ozone_imputado  , x = Solar.R),
             color = "red", alpha = 0.5)+
  labs(y = "Variável Ozone",
       x = "Variável Solar.R")
```



Os valores imputados correspondem aos valores mais prováveis pelo modelo. No entanto, o conjunto de valores imputados variam menos do que os valores observados.<!-- Pode ser que cada um dos pontos individuais seja o melhor no modelo, mas é muito improvável que os valores reais (mas não observados) de ozônio tivessem essa distribuição.--->. A *Regression imputation* também afeta a correlação, os pontos vermelhos têm uma correlação de 1, pois estão localizados em uma linha. Se os pontos vermelhos e azuis forem combinados,  a correlação aumenta de 0.35 para 0.39. 
A *Regression imputation* produz estimativas não viesadas  das médias sob MCAR, assim como a imputação da média, e dos pesos de regressão do
 modelo de imputação se as variáveis explicativas forem completas. 

Além disso, os coeficientes  da regressão são não viesados  sob MAR se os fatores que influenciam a falta fazem parte do modelo de regressão. 

No exemplo, isso corresponde à situação em que Solar.R explicaria quaisquer diferenças na probabilidade de falta de ozônio. Por outro lado, a variabilidade dos dados imputados é sistematicamente subestimada. 
<!---O grau de subestimação depende da variância explicada e da proporção de casos ausentes (Little e Rubin, 2002, p. 64).--->

 A imputação de valores preditos pode produzir imputações realistas se a predição estiver próxima da perfeição. Nesse caso, o método reconstrói as partes que faltam a partir dos dados disponíveis. 

<!--Em essência, não havia realmente nenhuma informação faltando em primeiro lugar, ela estava apenas codificada de uma forma diferente. É improvável que esse tipo de dados ausentes apareça na maioria dos aplicativos. --->

### Stochastic regression imputation

*Stochastic regression imputation*, imputação de regressão estocástica, é um refinamento da imputação de regressão que adiciona ruído às previsões. Isso terá um efeito descendente na correlação. Podemos imputar valores a variaável `Ozone`  por *Stochastic regression imputation* com o código:

```{r message=FALSE, warning=FALSE}
library(mice)
imp <- mice (airquality [, 1: 2], 
             method = "norm.nob", 
             m = 1, 
             maxit = 1, 
             seed = 1, 
             printFlag = F)

```

onde 

+ method = "norm.nob" requer um método de regressão estocástica simples. Este método  estima a intercepto, a inclinação, a variância residual e, em seguida, gera o valor imputado de acordo com essas especificações. 

+ seed = 1 torna a solução reproduzível. 


O gráfico abaixo apresenta os valores imputados por *Stochastic regression imputation*, os pontos vermelhos são os valores imputados.


```{r fig.align='center', fig.asp=.75, fig.cap='Stochastic regression inputation entre Ozone e Solar.R',  message=FALSE, warning=FALSE, out.width='80%'}

xyplot(imp,  Ozone ~ Solar.R, pch=c(16,20), cex=c(0.8,1.5),
       xlab = "Variável Solar.R",
       ylab = "variável Ozone")

```

Observe as estatísticas descrivivas dos valores imputados:

```{r}

# Estatística Descritiva var Ozone
Ozone_imputado <- imp$imp$Ozone
summary(Ozone_imputado)

#Estatística Descritica var. Solar.R

Solar.R_imputado <- imp$imp$Solar.R
summary(Solar.R_imputado)

```


A adição de ruído às previsões aumenta a variabilidade dos valores imputados. Observe:

1. Há imputações com valores negativos. Esses valores são implausíveis, uma vez que não existem concentrações negativas de ozônio no mundo real.

2. Além disso, o limite superior da distribuição não é bem coberto.  A causa disso é que a relação nos dados observados é um tanto heterocedástica. A variabilidade do ozônio parece aumentar até o nível de radiação solar de 250 langleys, e diminui depois disso. 

3. Não está claro se este é um fenômeno meteorológico genuíno, o modelo de imputação não levou isso  em consideração.

A *Stochastic regression inputation*  preserva não só os coeficientes  de uma  regressão, mas também a correlação entre as variáveis .

A *Stochastic regression inputation* não resolve todos os problemas e há  muitas sutilezas que precisam ser abordadas, entretanto  e forma a base de técnicas de imputação mais avançadas.